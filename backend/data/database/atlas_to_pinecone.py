"""
MongoDB Atlas â†’ Pinecone Embedding Upload
- Sadece embedding yÃ¼kleme iÅŸlemi
- Ä°ki ayrÄ± index: router (abstract) ve unified (full-text)
- Veri tekrarÄ± yok
"""

import pymongo
from pinecone import Pinecone, ServerlessSpec
from tqdm import tqdm
import time
from datetime import datetime, timezone
import os
from dotenv import load_dotenv
from typing import Dict

load_dotenv()

# ============================================================
# KONFÄ°GÃœRASYON
# ============================================================

# MongoDB Atlas
MONGO_URI = os.getenv("MONGO_URI")
DB_NAME = os.getenv("DB_NAME", "medicrew")
CHUNKS_COLLECTION = "paper_chunks"

# Pinecone
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT", "us-east-1")
ROUTER_INDEX_NAME = "medical-abstracts-router"
UNIFIED_INDEX_NAME = "medical-papers-unified"
EMBEDDING_DIMENSION = 768
METRIC = "cosine"

# Ä°ÅŸlem
UPSERT_BATCH_SIZE = 100
FETCH_BATCH_SIZE = 500
RATE_LIMIT_DELAY = 0.5

# ============================================================
# BAÄLANTI KURMA
# ============================================================

def setup_mongodb():
    """MongoDB Atlas baÄŸlantÄ±sÄ±"""
    print("ğŸ”— MongoDB Atlas'a baÄŸlanÄ±lÄ±yor...")
    try:
        client = pymongo.MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
        db = client[DB_NAME]
        chunks_collection = db[CHUNKS_COLLECTION]
        client.server_info()
        print(f"âœ… MongoDB baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±: {CHUNKS_COLLECTION}")
        return chunks_collection
    except Exception as e:
        print(f"âŒ MongoDB baÄŸlantÄ± hatasÄ±: {e}")
        exit(1)

def setup_pinecone_index(index_name: str, force_recreate: bool = False):
    """Pinecone index kurulumu"""
    print(f"\nğŸ”„ Pinecone index hazÄ±rlanÄ±yor: {index_name}")
    
    try:
        pc = Pinecone(api_key=PINECONE_API_KEY)
        existing_indexes = pc.list_indexes().names()
        
        if index_name in existing_indexes:
            if force_recreate:
                print(f"âš ï¸ Mevcut index siliniyor: {index_name}")
                pc.delete_index(index_name)
                print("Index silindi. Bekleniyor...")
                time.sleep(10)
                
                print(f"Yeni index oluÅŸturuluyor: {index_name}")
                pc.create_index(
                    name=index_name,
                    dimension=EMBEDDING_DIMENSION,
                    metric=METRIC,
                    spec=ServerlessSpec(cloud='aws', region=PINECONE_ENVIRONMENT)
                )
                print("âœ… Yeni index oluÅŸturuldu")
                time.sleep(2)
            else:
                print(f"âœ… Mevcut index kullanÄ±lÄ±yor: {index_name}")
        else:
            print(f"Yeni index oluÅŸturuluyor: {index_name}")
            pc.create_index(
                name=index_name,
                dimension=EMBEDDING_DIMENSION,
                metric=METRIC,
                spec=ServerlessSpec(cloud='aws', region=PINECONE_ENVIRONMENT)
            )
            print(f"âœ… Index oluÅŸturuldu: {index_name}")
            time.sleep(2)
        
        index = pc.Index(index_name)
        stats = index.describe_index_stats()
        vector_count = stats.get('total_vector_count', 0)
        print(f"ğŸ“Š Mevcut vektÃ¶r sayÄ±sÄ± ({index_name}): {vector_count:,}")
        
        return index
        
    except Exception as e:
        print(f"âŒ Pinecone hatasÄ± ({index_name}): {e}")
        exit(1)

# ============================================================
# YÃœKLEME FONKSÄ°YONLARI
# ============================================================

def prepare_router_vector(chunk: Dict) -> Dict:
    """Router index iÃ§in vektÃ¶r hazÄ±rlama (sadece abstract'lar)"""
    vector_id = f"abstract_{chunk['pmid']}"
    
    metadata = {
        'pmid': chunk['pmid'],
        'title': chunk.get('title', '')[:500],
        'journal': chunk.get('journal', '')[:200],
        'year': chunk.get('year'),
        'chunk_type': 'abstract',
        'text_preview': chunk['text'][:200]
    }
    
    # None deÄŸerleri temizle
    metadata = {k: v for k, v in metadata.items() if v is not None}
    
    return {
        'id': vector_id,
        'values': chunk['embedding'],
        'metadata': metadata
    }

def prepare_unified_vector(chunk: Dict) -> Dict:
    """Unified index iÃ§in vektÃ¶r hazÄ±rlama (sadece full-text chunk'lar)"""
    vector_id = f"{chunk['pmid']}_chunk_{chunk['chunk_index']}"
    
    metadata = {
        'pmid': chunk['pmid'],
        'chunk_index': chunk['chunk_index'],
        'chunk_type': 'full_text',
        'section': chunk.get('section', '')[:100],
        'title': chunk.get('title', '')[:500],
        'journal': chunk.get('journal', '')[:200],
        'year': chunk.get('year'),
        'text_preview': chunk['text'][:200],
        'token_count': chunk.get('token_count')
    }
    
    # None deÄŸerleri temizle
    metadata = {k: v for k, v in metadata.items() if v is not None}
    
    return {
        'id': vector_id,
        'values': chunk['embedding'],
        'metadata': metadata
    }

def upload_to_router_index(chunks_collection, router_index):
    """Sadece ABSTRACT'larÄ± router index'e yÃ¼kle"""
    
    total_abstracts = chunks_collection.count_documents({
        'embedded': True,
        'is_abstract': True,
        'synced_to_router': False
    })
    
    if total_abstracts == 0:
        print("â„¹ï¸ Router index iÃ§in yeni abstract bulunamadÄ±")
        return
    
    print(f"\nğŸš€ ROUTER INDEX: {total_abstracts:,} abstract yÃ¼kleniyor...")
    
    uploaded = 0
    with tqdm(total=total_abstracts, desc="Abstract'lar", unit="vec") as pbar:
        while uploaded < total_abstracts:
            chunks = list(chunks_collection.find({
                'embedded': True,
                'is_abstract': True,
                'synced_to_router': False
            }, limit=FETCH_BATCH_SIZE))
            
            if not chunks:
                break
            
            for i in range(0, len(chunks), UPSERT_BATCH_SIZE):
                batch = chunks[i:i + UPSERT_BATCH_SIZE]
                vectors = [prepare_router_vector(chunk) for chunk in batch]
                
                try:
                    router_index.upsert(vectors=vectors)
                    
                    # Sync flag'ini gÃ¼ncelle
                    chunk_ids = [chunk['_id'] for chunk in batch]
                    chunks_collection.update_many(
                        {'_id': {'$in': chunk_ids}},
                        {
                            '$set': {
                                'synced_to_router': True,
                                'router_synced_at': datetime.now(timezone.utc)
                            }
                        }
                    )
                    
                    uploaded += len(batch)
                    pbar.update(len(batch))
                    time.sleep(RATE_LIMIT_DELAY)
                    
                except Exception as e:
                    print(f"\nâŒ Router yÃ¼kleme hatasÄ±: {e}")
                    continue

def upload_to_unified_index(chunks_collection, unified_index):
    """Sadece FULL-TEXT chunk'larÄ±nÄ± unified index'e yÃ¼kle"""
    
    total_chunks = chunks_collection.count_documents({
        'embedded': True,
        'is_abstract': False,
        'synced_to_unified': False
    })
    
    if total_chunks == 0:
        print("â„¹ï¸ Unified index iÃ§in yeni full-text chunk bulunamadÄ±")
        return
    
    print(f"\nğŸ¯ UNIFIED INDEX: {total_chunks:,} full-text chunk yÃ¼kleniyor...")
    
    uploaded = 0
    with tqdm(total=total_chunks, desc="Full-Text", unit="vec") as pbar:
        while uploaded < total_chunks:
            chunks = list(chunks_collection.find({
                'embedded': True,
                'is_abstract': False,
                'synced_to_unified': False
            }, limit=FETCH_BATCH_SIZE))
            
            if not chunks:
                break
            
            for i in range(0, len(chunks), UPSERT_BATCH_SIZE):
                batch = chunks[i:i + UPSERT_BATCH_SIZE]
                vectors = [prepare_unified_vector(chunk) for chunk in batch]
                
                try:
                    unified_index.upsert(vectors=vectors)
                    
                    # Sync flag'ini gÃ¼ncelle
                    chunk_ids = [chunk['_id'] for chunk in batch]
                    chunks_collection.update_many(
                        {'_id': {'$in': chunk_ids}},
                        {
                            '$set': {
                                'synced_to_unified': True,
                                'unified_synced_at': datetime.now(timezone.utc)
                            }
                        }
                    )
                    
                    uploaded += len(batch)
                    pbar.update(len(batch))
                    time.sleep(RATE_LIMIT_DELAY)
                    
                except Exception as e:
                    print(f"\nâŒ Unified yÃ¼kleme hatasÄ±: {e}")
                    continue

# ============================================================
# DOÄRULAMA
# ============================================================

def verify_upload(chunks_collection, router_index, unified_index):
    """YÃ¼kleme sonrasÄ± doÄŸrulama"""
    print("\n" + "="*70)
    print("ğŸ“Š YÃœKLEME DOÄRULAMA")
    print("="*70)
    
    # MongoDB istatistikleri
    total_abstracts = chunks_collection.count_documents({'is_abstract': True})
    total_fulltext = chunks_collection.count_documents({'is_abstract': False})
    
    router_synced = chunks_collection.count_documents({'synced_to_router': True})
    unified_synced = chunks_collection.count_documents({'synced_to_unified': True})
    
    print(f"\nğŸ“ˆ MONGODB DURUMU:")
    print(f"  Toplam abstract: {total_abstracts:,}")
    print(f"  Toplam full-text: {total_fulltext:,}")
    print(f"  Router'a sync: {router_synced:,}/{total_abstracts:,}")
    print(f"  Unified'e sync: {unified_synced:,}/{total_fulltext:,}")
    
    # Pinecone istatistikleri
    router_stats = router_index.describe_index_stats()
    unified_stats = unified_index.describe_index_stats()
    
    print(f"\nğŸ¯ PINECONE DURUMU:")
    print(f"  {ROUTER_INDEX_NAME}: {router_stats.get('total_vector_count', 0):,} vektÃ¶r")
    print(f"  {UNIFIED_INDEX_NAME}: {unified_stats.get('total_vector_count', 0):,} vektÃ¶r")
    
    if router_synced == total_abstracts and unified_synced == total_fulltext:
        print(f"\nâœ… TÃœM veriler baÅŸarÄ±yla sync edildi!")
    else:
        print(f"\nâš ï¸  Sync tamamlanmadÄ±:")
        if router_synced < total_abstracts:
            print(f"   - Router: {total_abstracts - router_synced:,} abstract eksik")
        if unified_synced < total_fulltext:
            print(f"   - Unified: {total_fulltext - unified_synced:,} chunk eksik")

def reset_sync_flags(chunks_collection):
    """Sync flag'lerini sÄ±fÄ±rla (yeniden yÃ¼kleme iÃ§in)"""
    print("\nğŸ”„ Sync flag'leri sÄ±fÄ±rlanÄ±yor...")
    
    chunks_collection.update_many(
        {},
        {
            '$set': {
                'synced_to_router': False,
                'synced_to_unified': False
            },
            '$unset': {
                'router_synced_at': '',
                'unified_synced_at': ''
            }
        }
    )
    
    print("âœ… Sync flag'leri sÄ±fÄ±rlandÄ±")

# ============================================================
# ANA Ä°ÅLEM
# ============================================================

def main():
    """Ana yÃ¼kleme iÅŸlemi"""
    print("="*70)
    print("MongoDB Atlas â†’ Pinecone Embedding YÃ¼kleme")
    print("="*70)
    print("ğŸ¯ STRATEJÄ°:")
    print("   - ROUTER INDEX: Sadece abstract'lar")
    print("   - UNIFIED INDEX: Sadece full-text chunk'lar")
    print("   - VERÄ° TEKRARI: Yok")
    print()
    
    try:
        # BaÄŸlantÄ±larÄ± kur
        chunks_collection = setup_mongodb()
        
        # KullanÄ±cÄ± seÃ§imi
        print("\n" + "-"*70)
        print("Pinecone SeÃ§enekleri:")
        print("1. Mevcut index'leri kullan (yeni vektÃ¶rleri ekle)")
        print("2. TEMÄ°Z BAÅLANGIÃ‡ - Index'leri sil ve yeniden oluÅŸtur")
        
        choice = input("\nSeÃ§im (1/2): ").strip()
        
        force_recreate = False
        if choice == "2":
            print("ğŸš¨ UYARI: Bu iÅŸlem tÃ¼m index'leri SÄ°LECEK!")
            confirm = input("Onay iÃ§in 'SIL' yazÄ±n: ")
            if confirm == "SIL":
                force_recreate = True
            else:
                print("âŒ Ä°ÅŸlem iptal edildi")
                return
        
        # Index'leri kur
        router_index = setup_pinecone_index(ROUTER_INDEX_NAME, force_recreate)
        unified_index = setup_pinecone_index(UNIFIED_INDEX_NAME, force_recreate)
        
        if force_recreate:
            reset_sync_flags(chunks_collection)
        
        # YÃ¼kleme iÅŸlemleri
        upload_to_router_index(chunks_collection, router_index)
        upload_to_unified_index(chunks_collection, unified_index)
        
        # DoÄŸrulama
        verify_upload(chunks_collection, router_index, unified_index)
        
        print("\n" + "="*70)
        print("âœ… EMBEDDING YÃœKLEME TAMAMLANDI!")
        print("="*70)
        print("Sonraki adÄ±m: Retrieval pipeline'Ä±nÄ± kurmak iÃ§in hazÄ±r!")
        
    except KeyboardInterrupt:
        print("\n\nâŒ Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan iptal edildi")
    except Exception as e:
        print(f"\nâŒ Hata: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()